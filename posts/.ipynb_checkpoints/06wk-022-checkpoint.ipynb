{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1701eef1-e07d-4f9c-9454-2da294cf9253",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"06wk-022: 취업+각종영어점수, 다중공선성\"\n",
    "author: \"최규빈\"\n",
    "date: \"10/05/2023\"\n",
    "bibliography: ref.bib\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714149a9",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630eaec",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59089a4-68c0-445b-a878-14a36d010007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2ee22",
   "metadata": {},
   "source": [
    "# 3. 상상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905de4f",
   "metadata": {},
   "source": [
    "`-` 아래와 같은 가짜뉴스를 읽어보자.^[제가 ChatGPT를 이용하여 생성한 가짜뉴스입니다. 뉴스는 실제사실을 반영한 것이 아닙니다.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c35b4f",
   "metadata": {},
   "source": [
    "**헤드라인**: \"텝스와 다른 영어 인증 시험들, 결국은 토익과 비슷한 결과를 보여준다?\"\n",
    "\n",
    "---\n",
    "\n",
    "**본문**:\n",
    "\n",
    "최근 몇 년 동안, 토익의 신뢰성에 대한 논란이 계속되어 왔습니다. 이러한 배경 속에서 텝스(TEPS), 토플(TOEFL) 등 여러 새로운 영어 능력 평가 시험이 등장하였습니다. 많은 학생들과 직장인들은 이러한 새로운 시험들이 토익보다 더 신뢰성 있고 현실적인 능력을 평가할 것이라는 기대감을 가지고 있었습니다.\n",
    "\n",
    "그러나 최근에 발표된 연구결과에 따르면, 텝스와 다른 영어 인증 시험들도 결국에는 토익과 매우 비슷한 성적 분포와 결과를 보여주었다고 합니다. 연구 팀은 여러 시험들간의 점수 분포와 성적의 상관관계를 분석한 결과, 대부분의 시험들이 실제 영어 능력에 대해 유사한 평가를 제공한다는 결론을 내렸습니다.\n",
    "\n",
    "\"많은 사람들이 새로운 시험들이 더 현실적이거나 다양한 영어 능력을 평가할 것이라 기대했지만, 실제로는 모든 시험들이 비슷한 결과를 보여주었습니다.\" 라며 연구 팀의 대표는 이렇게 언급하였습니다.\n",
    "\n",
    "이러한 연구결과는 영어 능력 평가 시험의 표준화와 신뢰성에 대한 논의를 새롭게 불러일으킬 것으로 보입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d9a75",
   "metadata": {},
   "source": [
    "`-` 이 뉴스에 근거하여 아래의 가짜자료를 생성했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df31636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment_score</th>\n",
       "      <th>gpa</th>\n",
       "      <th>toeic</th>\n",
       "      <th>toeic0</th>\n",
       "      <th>toeic1</th>\n",
       "      <th>toeic2</th>\n",
       "      <th>toeic3</th>\n",
       "      <th>toeic4</th>\n",
       "      <th>toeic5</th>\n",
       "      <th>toeic6</th>\n",
       "      <th>...</th>\n",
       "      <th>toeic490</th>\n",
       "      <th>toeic491</th>\n",
       "      <th>toeic492</th>\n",
       "      <th>toeic493</th>\n",
       "      <th>toeic494</th>\n",
       "      <th>toeic495</th>\n",
       "      <th>toeic496</th>\n",
       "      <th>toeic497</th>\n",
       "      <th>toeic498</th>\n",
       "      <th>toeic499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.949314</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>135</td>\n",
       "      <td>134.889567</td>\n",
       "      <td>132.466381</td>\n",
       "      <td>134.328746</td>\n",
       "      <td>133.692285</td>\n",
       "      <td>134.490387</td>\n",
       "      <td>133.482738</td>\n",
       "      <td>135.805902</td>\n",
       "      <td>...</td>\n",
       "      <td>134.568925</td>\n",
       "      <td>135.248135</td>\n",
       "      <td>135.557690</td>\n",
       "      <td>134.307587</td>\n",
       "      <td>136.115518</td>\n",
       "      <td>136.895841</td>\n",
       "      <td>135.599610</td>\n",
       "      <td>134.083179</td>\n",
       "      <td>135.125554</td>\n",
       "      <td>134.320048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.861725</td>\n",
       "      <td>0.355496</td>\n",
       "      <td>935</td>\n",
       "      <td>933.897710</td>\n",
       "      <td>934.928312</td>\n",
       "      <td>935.665096</td>\n",
       "      <td>934.115679</td>\n",
       "      <td>934.204277</td>\n",
       "      <td>935.213653</td>\n",
       "      <td>935.551083</td>\n",
       "      <td>...</td>\n",
       "      <td>932.507220</td>\n",
       "      <td>934.449154</td>\n",
       "      <td>935.213485</td>\n",
       "      <td>935.216839</td>\n",
       "      <td>935.039467</td>\n",
       "      <td>935.400347</td>\n",
       "      <td>934.172674</td>\n",
       "      <td>935.189259</td>\n",
       "      <td>936.578955</td>\n",
       "      <td>937.278620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.582663</td>\n",
       "      <td>2.228435</td>\n",
       "      <td>485</td>\n",
       "      <td>483.020037</td>\n",
       "      <td>484.161879</td>\n",
       "      <td>486.041920</td>\n",
       "      <td>482.954745</td>\n",
       "      <td>485.891348</td>\n",
       "      <td>484.849052</td>\n",
       "      <td>485.410756</td>\n",
       "      <td>...</td>\n",
       "      <td>484.863750</td>\n",
       "      <td>485.516249</td>\n",
       "      <td>484.523790</td>\n",
       "      <td>486.036836</td>\n",
       "      <td>485.011074</td>\n",
       "      <td>485.637154</td>\n",
       "      <td>484.001982</td>\n",
       "      <td>485.544729</td>\n",
       "      <td>485.815829</td>\n",
       "      <td>485.042914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.919694</td>\n",
       "      <td>1.179701</td>\n",
       "      <td>65</td>\n",
       "      <td>66.780387</td>\n",
       "      <td>67.388852</td>\n",
       "      <td>65.622595</td>\n",
       "      <td>62.763278</td>\n",
       "      <td>65.935953</td>\n",
       "      <td>67.288798</td>\n",
       "      <td>66.314210</td>\n",
       "      <td>...</td>\n",
       "      <td>64.151163</td>\n",
       "      <td>64.677268</td>\n",
       "      <td>66.340589</td>\n",
       "      <td>64.291130</td>\n",
       "      <td>64.540950</td>\n",
       "      <td>66.728237</td>\n",
       "      <td>65.474820</td>\n",
       "      <td>65.725247</td>\n",
       "      <td>65.015707</td>\n",
       "      <td>65.399658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.286851</td>\n",
       "      <td>3.962356</td>\n",
       "      <td>445</td>\n",
       "      <td>444.348116</td>\n",
       "      <td>445.520801</td>\n",
       "      <td>446.419087</td>\n",
       "      <td>442.715198</td>\n",
       "      <td>445.043974</td>\n",
       "      <td>444.849464</td>\n",
       "      <td>446.178144</td>\n",
       "      <td>...</td>\n",
       "      <td>444.993117</td>\n",
       "      <td>444.999768</td>\n",
       "      <td>445.773163</td>\n",
       "      <td>444.924819</td>\n",
       "      <td>442.703987</td>\n",
       "      <td>445.118233</td>\n",
       "      <td>445.119561</td>\n",
       "      <td>446.214723</td>\n",
       "      <td>444.983397</td>\n",
       "      <td>444.455462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>7.002081</td>\n",
       "      <td>4.288465</td>\n",
       "      <td>280</td>\n",
       "      <td>280.520486</td>\n",
       "      <td>281.060157</td>\n",
       "      <td>281.291354</td>\n",
       "      <td>280.816827</td>\n",
       "      <td>280.867509</td>\n",
       "      <td>279.748219</td>\n",
       "      <td>280.956388</td>\n",
       "      <td>...</td>\n",
       "      <td>280.864668</td>\n",
       "      <td>280.261168</td>\n",
       "      <td>278.871055</td>\n",
       "      <td>280.267526</td>\n",
       "      <td>279.792068</td>\n",
       "      <td>279.931181</td>\n",
       "      <td>280.606405</td>\n",
       "      <td>280.710435</td>\n",
       "      <td>279.602746</td>\n",
       "      <td>280.472047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5.431050</td>\n",
       "      <td>2.601212</td>\n",
       "      <td>310</td>\n",
       "      <td>310.015294</td>\n",
       "      <td>310.003728</td>\n",
       "      <td>308.680788</td>\n",
       "      <td>309.179518</td>\n",
       "      <td>310.908038</td>\n",
       "      <td>308.580682</td>\n",
       "      <td>308.720718</td>\n",
       "      <td>...</td>\n",
       "      <td>310.670717</td>\n",
       "      <td>310.872724</td>\n",
       "      <td>309.631197</td>\n",
       "      <td>309.723108</td>\n",
       "      <td>309.624440</td>\n",
       "      <td>310.207927</td>\n",
       "      <td>308.519863</td>\n",
       "      <td>309.858127</td>\n",
       "      <td>310.602814</td>\n",
       "      <td>310.841082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.088812</td>\n",
       "      <td>0.042323</td>\n",
       "      <td>225</td>\n",
       "      <td>225.226422</td>\n",
       "      <td>225.738373</td>\n",
       "      <td>223.342848</td>\n",
       "      <td>226.416036</td>\n",
       "      <td>223.478492</td>\n",
       "      <td>225.080199</td>\n",
       "      <td>224.896846</td>\n",
       "      <td>...</td>\n",
       "      <td>223.252383</td>\n",
       "      <td>226.178697</td>\n",
       "      <td>225.494945</td>\n",
       "      <td>225.154573</td>\n",
       "      <td>225.254684</td>\n",
       "      <td>224.711397</td>\n",
       "      <td>225.259744</td>\n",
       "      <td>223.700222</td>\n",
       "      <td>225.700224</td>\n",
       "      <td>225.120175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3.806388</td>\n",
       "      <td>1.041416</td>\n",
       "      <td>320</td>\n",
       "      <td>321.135794</td>\n",
       "      <td>319.880713</td>\n",
       "      <td>319.759936</td>\n",
       "      <td>321.071771</td>\n",
       "      <td>320.085155</td>\n",
       "      <td>320.657430</td>\n",
       "      <td>320.802495</td>\n",
       "      <td>...</td>\n",
       "      <td>319.875882</td>\n",
       "      <td>321.006234</td>\n",
       "      <td>319.054499</td>\n",
       "      <td>320.498798</td>\n",
       "      <td>320.407021</td>\n",
       "      <td>323.002351</td>\n",
       "      <td>319.496038</td>\n",
       "      <td>320.011256</td>\n",
       "      <td>319.304070</td>\n",
       "      <td>320.418582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6.739095</td>\n",
       "      <td>3.626883</td>\n",
       "      <td>375</td>\n",
       "      <td>376.032149</td>\n",
       "      <td>373.131026</td>\n",
       "      <td>374.800140</td>\n",
       "      <td>374.541924</td>\n",
       "      <td>375.363948</td>\n",
       "      <td>375.758260</td>\n",
       "      <td>375.045161</td>\n",
       "      <td>...</td>\n",
       "      <td>375.452139</td>\n",
       "      <td>374.790209</td>\n",
       "      <td>374.247366</td>\n",
       "      <td>372.755630</td>\n",
       "      <td>373.711254</td>\n",
       "      <td>376.621000</td>\n",
       "      <td>373.979317</td>\n",
       "      <td>374.788932</td>\n",
       "      <td>374.153385</td>\n",
       "      <td>373.678255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     employment_score       gpa  toeic      toeic0      toeic1      toeic2  \\\n",
       "0           -0.949314  0.051535    135  134.889567  132.466381  134.328746   \n",
       "1            4.861725  0.355496    935  933.897710  934.928312  935.665096   \n",
       "2            5.582663  2.228435    485  483.020037  484.161879  486.041920   \n",
       "3            3.919694  1.179701     65   66.780387   67.388852   65.622595   \n",
       "4            8.286851  3.962356    445  444.348116  445.520801  446.419087   \n",
       "..                ...       ...    ...         ...         ...         ...   \n",
       "495          7.002081  4.288465    280  280.520486  281.060157  281.291354   \n",
       "496          5.431050  2.601212    310  310.015294  310.003728  308.680788   \n",
       "497          0.088812  0.042323    225  225.226422  225.738373  223.342848   \n",
       "498          3.806388  1.041416    320  321.135794  319.880713  319.759936   \n",
       "499          6.739095  3.626883    375  376.032149  373.131026  374.800140   \n",
       "\n",
       "         toeic3      toeic4      toeic5      toeic6  ...    toeic490  \\\n",
       "0    133.692285  134.490387  133.482738  135.805902  ...  134.568925   \n",
       "1    934.115679  934.204277  935.213653  935.551083  ...  932.507220   \n",
       "2    482.954745  485.891348  484.849052  485.410756  ...  484.863750   \n",
       "3     62.763278   65.935953   67.288798   66.314210  ...   64.151163   \n",
       "4    442.715198  445.043974  444.849464  446.178144  ...  444.993117   \n",
       "..          ...         ...         ...         ...  ...         ...   \n",
       "495  280.816827  280.867509  279.748219  280.956388  ...  280.864668   \n",
       "496  309.179518  310.908038  308.580682  308.720718  ...  310.670717   \n",
       "497  226.416036  223.478492  225.080199  224.896846  ...  223.252383   \n",
       "498  321.071771  320.085155  320.657430  320.802495  ...  319.875882   \n",
       "499  374.541924  375.363948  375.758260  375.045161  ...  375.452139   \n",
       "\n",
       "       toeic491    toeic492    toeic493    toeic494    toeic495    toeic496  \\\n",
       "0    135.248135  135.557690  134.307587  136.115518  136.895841  135.599610   \n",
       "1    934.449154  935.213485  935.216839  935.039467  935.400347  934.172674   \n",
       "2    485.516249  484.523790  486.036836  485.011074  485.637154  484.001982   \n",
       "3     64.677268   66.340589   64.291130   64.540950   66.728237   65.474820   \n",
       "4    444.999768  445.773163  444.924819  442.703987  445.118233  445.119561   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "495  280.261168  278.871055  280.267526  279.792068  279.931181  280.606405   \n",
       "496  310.872724  309.631197  309.723108  309.624440  310.207927  308.519863   \n",
       "497  226.178697  225.494945  225.154573  225.254684  224.711397  225.259744   \n",
       "498  321.006234  319.054499  320.498798  320.407021  323.002351  319.496038   \n",
       "499  374.790209  374.247366  372.755630  373.711254  376.621000  373.979317   \n",
       "\n",
       "       toeic497    toeic498    toeic499  \n",
       "0    134.083179  135.125554  134.320048  \n",
       "1    935.189259  936.578955  937.278620  \n",
       "2    485.544729  485.815829  485.042914  \n",
       "3     65.725247   65.015707   65.399658  \n",
       "4    446.214723  444.983397  444.455462  \n",
       "..          ...         ...         ...  \n",
       "495  280.710435  279.602746  280.472047  \n",
       "496  309.858127  310.602814  310.841082  \n",
       "497  223.700222  225.700224  225.120175  \n",
       "498  320.011256  319.304070  320.418582  \n",
       "499  374.788932  374.153385  373.678255  \n",
       "\n",
       "[500 rows x 503 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment_manytoeic.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730c3ab",
   "metadata": {},
   "source": [
    "- toeic0,toeic1,... 등은 토익과 유사한 새로운 시험들을 의미함. (실제 점수는 정수이겠지만 편의상 소수점으로 사용하였음)\n",
    "- employmet_score는 회사에 내부적으로 정의된 채점기준표이며, 이 기준표에 의하여 일정점수 이상인 사람은 합격하고, 그렇지 않은 사람은 불합격한다고 가정함. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f4604",
   "metadata": {},
   "source": [
    "`-` 비밀: 사실 저는 데이터를 아래의 공식에 따라서 만들었어요.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac525a-bc1f-4c83-a62f-71799eaf5288",
   "metadata": {},
   "source": [
    "```\n",
    "employment_score = toeic*1/200 + gpa*1.3 + random \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f729b",
   "metadata": {},
   "source": [
    "# 4. 잘못된 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3d3da29f-eb94-4950-9931-3e3a823c5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = sklearn.model_selection.train_test_split(df,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aaff234e-cead-466e-bfc1-e9538b0c807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['employment_score'],axis=1)\n",
    "y = df_train[['employment_score']]\n",
    "XX = df_test.drop(['employment_score'],axis=1)\n",
    "yy = df_test[['employment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7045ffa-40b3-4a27-aa72-c6b2eefcdd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "90f5f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 502)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f68283fb-4ce1-483f-8f46-af6e37030888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4788d2e2-6973-413e-aba4-07c3ff817f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.02112402e+00, -2.36677547e-03,  3.85523072e-02,\n",
       "          3.38623268e-02, -2.93432251e-02, -8.23255968e-02,\n",
       "         -2.83792390e-02, -3.30451680e-02, -3.59693327e-02,\n",
       "         -3.10135375e-02,  4.94534726e-02,  9.13078604e-02,\n",
       "          2.19221569e-02,  7.60323862e-02, -1.12324645e-02,\n",
       "          6.11014041e-02,  7.33509312e-02,  5.81189572e-02,\n",
       "         -9.38924796e-02, -6.90024776e-03, -8.91948888e-03,\n",
       "          1.98972471e-02, -3.48094590e-02, -1.39698116e-02,\n",
       "          4.57744732e-02, -7.52517020e-02, -1.20673156e-03,\n",
       "         -3.06126049e-02,  3.47035620e-03, -6.98785901e-02,\n",
       "         -6.39852251e-02,  3.09712557e-02, -1.69024490e-01,\n",
       "         -5.81227554e-03,  8.28833397e-02,  4.46112770e-02,\n",
       "         -1.04920534e-01,  4.53796358e-02, -3.62899835e-03,\n",
       "          2.36434638e-02, -3.09819376e-02,  1.03528073e-01,\n",
       "          8.55996278e-02,  4.71787798e-02, -1.83272849e-02,\n",
       "         -2.63809229e-02,  8.80727421e-02,  5.34362626e-02,\n",
       "          5.70442025e-02, -1.96062839e-02, -8.07072325e-02,\n",
       "         -6.18870402e-03, -1.42632989e-01, -2.16704165e-02,\n",
       "          5.72968158e-02, -1.08218361e-02, -6.05512616e-02,\n",
       "         -7.91124231e-02,  9.90442328e-02,  1.23071587e-01,\n",
       "          6.12439197e-02, -7.35826850e-03,  7.72779710e-02,\n",
       "         -1.23138559e-02, -1.70240337e-01,  2.48262896e-02,\n",
       "         -1.28177753e-02, -9.34980400e-02,  1.73631902e-02,\n",
       "         -2.74123570e-02, -1.23429315e-01, -6.36588921e-02,\n",
       "         -5.79106545e-02, -4.59984064e-02,  7.91648985e-02,\n",
       "         -5.81344305e-02,  6.00382284e-02,  9.71515353e-02,\n",
       "          8.30895524e-02, -9.55928263e-02, -5.08409283e-03,\n",
       "          1.19146114e-02,  4.97364198e-02,  1.25862009e-01,\n",
       "         -4.76259912e-02,  2.86036179e-02, -1.73158500e-03,\n",
       "          2.75241272e-02, -1.01862535e-02,  7.39374949e-02,\n",
       "          7.88123906e-02, -7.91063985e-02,  3.24109686e-03,\n",
       "         -6.90837634e-02, -2.78003899e-02,  2.40906669e-03,\n",
       "          7.92850148e-02,  5.64507245e-02,  3.62075312e-02,\n",
       "          1.05744314e-01,  6.14079246e-02, -1.30983937e-02,\n",
       "         -1.00661879e-01,  1.52327898e-03,  1.01447275e-01,\n",
       "         -5.18665219e-02, -1.05134743e-02, -1.22418482e-02,\n",
       "          4.18889264e-02, -5.53596255e-02,  3.28401932e-02,\n",
       "          1.46697343e-01,  9.83667348e-02, -1.65347004e-02,\n",
       "         -1.21643851e-01,  3.46690767e-02, -1.58286180e-03,\n",
       "         -1.46900923e-02,  9.36106860e-02, -8.65241174e-02,\n",
       "          5.66207767e-03,  5.76166130e-02, -1.37747651e-02,\n",
       "         -5.10480420e-02,  1.38500614e-02,  3.48144516e-02,\n",
       "          9.43023559e-03, -1.59371866e-02,  1.16029923e-02,\n",
       "         -1.10922716e-02, -3.81182549e-02, -8.19472433e-02,\n",
       "         -7.59895988e-02,  1.53086077e-02, -6.80273134e-03,\n",
       "         -5.31132144e-02,  6.94663080e-02,  4.06838653e-02,\n",
       "          5.42612577e-02,  8.99365523e-02,  8.95961369e-03,\n",
       "         -3.52236347e-02, -1.20113121e-01, -7.21366777e-02,\n",
       "         -1.16095384e-02, -1.60706101e-01, -3.54898580e-02,\n",
       "         -1.58927476e-01, -7.98616509e-02, -4.56563918e-02,\n",
       "          1.62724040e-02,  5.22037474e-02,  8.16500088e-03,\n",
       "          6.33606583e-02,  2.30816083e-02,  7.43569807e-02,\n",
       "          3.87697911e-02,  1.07896528e-01,  1.97924418e-01,\n",
       "         -1.25684757e-01, -5.94043894e-02,  2.00462035e-02,\n",
       "          8.30175595e-03, -7.97723989e-02,  3.21814352e-02,\n",
       "         -8.44551267e-02, -7.00917978e-02,  1.42046274e-01,\n",
       "          2.10765945e-04,  3.36363057e-02,  1.58583829e-01,\n",
       "         -4.90975963e-02, -7.33121041e-03,  2.28974130e-02,\n",
       "          7.01101569e-02, -3.57865805e-02, -2.96804130e-02,\n",
       "          4.05534995e-02, -2.18515037e-02, -3.15341677e-02,\n",
       "         -4.16902366e-02,  6.22208304e-02, -1.29533902e-01,\n",
       "         -9.64964312e-02, -1.20777015e-02, -1.62049125e-03,\n",
       "          1.20426351e-02,  6.26004778e-02,  1.71237568e-02,\n",
       "         -4.71327539e-02,  7.62310813e-02,  1.96560803e-02,\n",
       "          6.35389872e-03,  3.89763113e-02, -2.84769455e-03,\n",
       "         -4.12673295e-02, -2.04271299e-01, -4.65820685e-02,\n",
       "         -3.93927988e-02, -3.10827168e-02, -6.23085182e-02,\n",
       "         -3.01263126e-04, -2.65259534e-02, -9.69835030e-02,\n",
       "         -1.30254726e-02,  6.00203997e-02, -6.09476670e-03,\n",
       "         -1.34547183e-01, -1.64393007e-02, -5.90124757e-02,\n",
       "         -6.34949137e-02,  8.14789410e-02,  1.58757669e-01,\n",
       "          8.62933543e-02,  5.45906241e-02,  1.24305969e-01,\n",
       "          2.26114277e-02, -3.46329241e-02,  1.88227598e-02,\n",
       "         -4.59435862e-02, -1.50772594e-01, -1.10359440e-02,\n",
       "          1.14595723e-02, -4.85162753e-02, -7.50037240e-02,\n",
       "          3.11793435e-02, -4.60665893e-02,  7.53159140e-02,\n",
       "         -1.00548276e-01, -6.14559765e-02, -6.83097296e-02,\n",
       "         -4.56887197e-03,  5.57495845e-02,  4.15810631e-02,\n",
       "          7.73247084e-03,  7.48764639e-02, -1.04533621e-02,\n",
       "         -1.55504197e-01,  5.50979700e-02, -8.87063607e-02,\n",
       "         -9.38158937e-04,  2.43556586e-02, -3.46149131e-02,\n",
       "         -1.27974404e-01,  2.01930557e-02, -7.59125567e-03,\n",
       "         -1.53953745e-02, -8.70657567e-02,  8.30284335e-02,\n",
       "         -8.78648565e-02,  2.24050421e-01,  1.28077189e-01,\n",
       "          2.66093957e-02,  3.71691873e-02, -3.06173150e-02,\n",
       "         -7.98619531e-03, -1.36248229e-01, -3.43411820e-02,\n",
       "          3.21209696e-02,  1.15105577e-01,  7.85356225e-03,\n",
       "         -7.73607836e-02, -2.00042344e-02, -1.76378602e-02,\n",
       "          3.71561661e-02, -8.99948108e-02,  3.03532642e-02,\n",
       "         -3.49680603e-02, -4.61380976e-02, -1.11821977e-02,\n",
       "          5.00281422e-02,  5.24786944e-02,  3.33403755e-02,\n",
       "         -3.92995044e-02,  7.10524687e-02, -6.13754797e-02,\n",
       "          4.47487701e-02, -1.94348543e-02, -2.57319617e-02,\n",
       "         -6.21305555e-02, -4.59424615e-02,  6.36477774e-02,\n",
       "          6.04673858e-02, -6.11520358e-02,  8.07904024e-02,\n",
       "         -2.44266950e-02, -4.34823903e-02,  5.86457632e-02,\n",
       "          9.03873170e-03, -7.72379320e-02,  5.57757012e-02,\n",
       "         -1.81965126e-03, -6.07917149e-02, -1.36173683e-01,\n",
       "          7.14324566e-02, -1.15082657e-02, -1.40847532e-02,\n",
       "         -9.87613293e-02, -9.19805250e-03, -3.19945696e-02,\n",
       "          1.08932415e-03,  7.86168897e-02,  7.37396997e-02,\n",
       "          5.13834350e-02, -4.59771927e-02, -6.27071892e-02,\n",
       "          9.30666921e-02,  4.37101473e-02,  2.84475381e-02,\n",
       "          5.18884259e-02, -1.94602969e-02, -3.68269158e-02,\n",
       "          3.85056525e-03, -6.00553877e-02,  1.14804041e-02,\n",
       "          1.23040086e-01,  3.17748486e-03,  5.96968109e-02,\n",
       "         -5.24423374e-02,  1.32018065e-01, -3.38380537e-02,\n",
       "         -3.42923451e-02,  2.91707540e-02, -4.31793962e-02,\n",
       "          1.93802195e-02, -1.40088128e-02,  3.24507299e-02,\n",
       "         -4.89623267e-02,  5.36975004e-02, -4.53545315e-03,\n",
       "          3.04436435e-02, -8.78086776e-02,  4.18790333e-02,\n",
       "          2.67113589e-02,  5.76757423e-02, -7.71513330e-02,\n",
       "          1.03055968e-01,  1.31656997e-01,  1.13940285e-01,\n",
       "          8.10249569e-02,  1.20379969e-01,  7.35017199e-02,\n",
       "         -6.90288543e-02, -1.50272442e-01, -6.60438401e-02,\n",
       "         -6.44098739e-02, -6.23378841e-02, -6.22515938e-02,\n",
       "         -3.80960994e-02,  1.54398408e-02,  3.42952814e-04,\n",
       "         -6.92531973e-02, -1.86073656e-03, -3.37259903e-02,\n",
       "         -7.29289175e-03, -6.79659717e-02,  2.47478090e-02,\n",
       "         -8.08186194e-02, -1.04072370e-01, -1.04320463e-01,\n",
       "          9.47065615e-02,  2.05039776e-02,  4.86148240e-02,\n",
       "          4.73821224e-02, -6.22665308e-02,  2.58131694e-02,\n",
       "          3.94198249e-02, -2.09076252e-01, -6.56104410e-03,\n",
       "          4.24690588e-03, -1.31985901e-01, -5.61666063e-02,\n",
       "         -1.41040364e-01,  5.79559017e-02,  9.53388940e-02,\n",
       "          2.97221849e-02, -7.21339353e-03,  2.06214841e-02,\n",
       "          5.22036934e-02,  2.61129571e-02, -6.53909971e-02,\n",
       "          1.70837869e-02,  5.54950506e-03,  8.66368610e-03,\n",
       "          7.49165531e-02, -9.83277647e-02,  7.46332132e-02,\n",
       "          5.31943533e-02,  6.37184011e-02,  7.58169730e-03,\n",
       "          6.55934319e-02,  2.69766292e-03, -7.70618466e-02,\n",
       "          1.52578789e-01,  4.55751337e-02, -6.07168471e-02,\n",
       "         -5.76532725e-02, -2.34312823e-02, -8.67955033e-02,\n",
       "          9.16474393e-02, -1.50663256e-01,  1.42411356e-02,\n",
       "          1.03479352e-01,  1.22991034e-01,  1.02516508e-01,\n",
       "          9.42812861e-03, -5.07282632e-02,  1.19524958e-01,\n",
       "         -3.16108580e-02,  4.36867513e-02,  7.48605820e-02,\n",
       "          1.42833612e-01, -4.73992587e-02,  5.18266117e-02,\n",
       "         -1.04910507e-02, -3.57537819e-03,  6.78909283e-02,\n",
       "         -5.35085016e-02, -5.59635989e-02, -1.71535797e-02,\n",
       "          8.39513059e-02, -3.19037931e-02,  5.41172825e-03,\n",
       "         -3.09136077e-02,  3.71478937e-02, -1.25582872e-02,\n",
       "         -3.11528875e-02,  2.20929976e-02, -5.76349068e-02,\n",
       "         -1.15652272e-01,  8.24484633e-02, -1.19151229e-02,\n",
       "          8.68064538e-04, -1.39262071e-02,  1.66074717e-01,\n",
       "          8.53423312e-02, -3.89791287e-02, -4.39046813e-02,\n",
       "         -1.65681771e-01,  4.80101151e-02, -8.90446077e-02,\n",
       "         -6.81494322e-02,  5.73417063e-03, -1.95498099e-02,\n",
       "          7.91973697e-02,  1.58000586e-03,  5.02952874e-02,\n",
       "          7.42321283e-02, -4.43705576e-02, -1.51569954e-01,\n",
       "         -7.50675686e-02, -9.55051198e-02,  6.17260872e-02,\n",
       "          1.33248346e-02,  4.93617316e-02,  3.56286450e-02,\n",
       "         -3.90262739e-02, -4.13074950e-02, -7.13692732e-02,\n",
       "          8.33029808e-02,  1.41648760e-01, -9.04257475e-03,\n",
       "         -5.61768800e-03,  8.07080059e-02,  1.93598608e-02,\n",
       "          8.60831677e-02, -2.04371893e-02, -2.44477488e-02,\n",
       "         -4.49802449e-02,  7.94351670e-02,  8.68065578e-02,\n",
       "         -1.10842276e-01, -1.12659663e-01,  8.71019102e-02,\n",
       "          4.29461185e-02,  2.33710943e-02, -5.19185679e-02,\n",
       "          2.88324323e-02,  5.10168742e-02, -6.78134089e-02,\n",
       "          2.90490450e-02,  3.73131696e-02,  1.85843467e-01,\n",
       "         -2.30043488e-01,  1.68686138e-01,  4.73779396e-02,\n",
       "          3.94794737e-02,  1.33842960e-01, -8.56977113e-02,\n",
       "          1.00610335e-02, -5.87598358e-03, -1.49747366e-01,\n",
       "          1.57368757e-02, -6.27412205e-02, -6.31240131e-02,\n",
       "          3.37142939e-02, -6.93336198e-02,  2.39104183e-03,\n",
       "         -7.39233889e-03,  4.60701985e-03,  6.13898214e-02,\n",
       "          6.59990287e-02]]),\n",
       " array([0.44843498]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.coef_,predictr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e6592",
   "metadata": {},
   "source": [
    "- 실제계수값은 `토익*0.005`, `GPA*1.3` 인데.. GPA는 얼추맞는거 같지만, 토익은 딱봐도 틀려보임.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b1393a2-3138-4212-b515-33154e267e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "766d702a-5446-46d9-9fd3-253d00701a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37707343690857686"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eba8f8",
   "metadata": {},
   "source": [
    "# 5. 제대로 분석했다면? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d2973",
   "metadata": {},
   "source": [
    "## A. `toeic`과 `gpa`가 유의미한 변수라는걸 눈치챘다면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad218142-a53d-4cb0-b3d6-6c5662b0f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['toeic','gpa']]\n",
    "y = df_train[['employment_score']]\n",
    "XX = df_test[['toeic','gpa']]\n",
    "yy = df_test[['employment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "29e3d75c-800c-4065-8b44-fabc524d9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b712a388-4a65-4688-bfc8-a9b4153445d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "571f071e-f7df-4113-bdd4-2e284edd2ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00517485, 1.30448417]]), array([-0.08665847]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.coef_,predictr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7ba0a143-a6ee-429f-aef8-7cb1a541a4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249262562780773"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ff348484-3008-4cc6-bf84-f588db1228f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347244826096045"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515b025",
   "metadata": {},
   "source": [
    "## B. 하다못해 `toeic0`과 `gpa`로 적합했다면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1185f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[['toeic0','gpa']]\n",
    "y = df_train[['employment_score']]\n",
    "XX = df_test[['toeic0','gpa']]\n",
    "yy = df_test[['employment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4951dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9abef74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22c7cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00517489, 1.30422841]]), array([-0.08635412]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.coef_,predictr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "27045386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249991103247842"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "355ff595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8346691714793039"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.score(XX,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cd41e",
   "metadata": {},
   "source": [
    "# 6. Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c1900",
   "metadata": {},
   "source": [
    "`-` 어렴풋한 감각: 쓸모없는 변수가 많이 있으면 오히려 모형의 적합도가 떨어진다. (규칙을 찾으면 안될것에서 규칙을 찾고있으니까 잘 될리가 없지)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f03437",
   "metadata": {},
   "source": [
    "`-` 쓸모없는 변수란 느낌이 드는 경우?\n",
    "\n",
    "- 경우1: 진짜 쓸모 없는거.. (X1= 부먹/찍먹, X2= 민초/민초X) $\\to$ 애초에 `X1`,`X2`을 보고 `y`를 맞출 생각이 들지 않어.. \n",
    "- 경우2: 실제론 쓸모 있는데, 대체자가 있는 경우. (X1= toeic, X2= 유사toeic) $\\to$ `X1` 을 보고 `y`를 맞출 것 같은 생각이 들어, 그리고 `X2`를 보고 `y`를 맞출 것 같은 생각도 들어. 그런데 `X1`이랑 `X2`는 너무 비슷해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a3a01",
   "metadata": {},
   "source": [
    "`-` 경우1, 경우2 모두 과대적합(overfitting)을 야기한다. 그리고 경우2와 같은 상황에서 발생하는 문제를 특별히 다중공선성이라고 칭한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd805c",
   "metadata": {},
   "source": [
    "\n",
    "`-` 다중공선성이 발생했을 경우 나타나는 특징\n",
    "\n",
    "1. 계수들의 추정값이 불안정하다^[사실 `toeic의 계수 + toeic0의 계수 + ... + toeic49의 계수` $\\approx$ `0.05` 이면 거진 올바른 추정아니야? 애초에 답이 여러개야]\n",
    "2. 과대적합 문제를 불러올 수 있음 \n",
    "3. 계수의 해석이 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49af2ca",
   "metadata": {},
   "source": [
    "`-` 의문: 그래서 해결방법은? 변수를 잘 보고 제거하라고??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
