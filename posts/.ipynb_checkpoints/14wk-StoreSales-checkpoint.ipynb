{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66371b5c-6d62-4853-967c-03b6604bd50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install autogluon.timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d18532-21ab-4639-8868-a1dd9f3073fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0907f68-1824-48aa-9afa-da8a425a437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading store-sales-time-series-forecasting.zip to /home/cgb2/Dropbox/07_lectures/2023-09-MP2023/posts\n",
      " 94%|███████████████████████████████████▌  | 20.0M/21.4M [00:01<00:00, 27.1MB/s]\n",
      "100%|██████████████████████████████████████| 21.4M/21.4M [00:01<00:00, 20.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c store-sales-time-series-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3ce242-56fc-46f9-86a2-c5ee0d42bff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  store-sales-time-series-forecasting.zip\n",
      "  inflating: data/holidays_events.csv  \n",
      "  inflating: data/oil.csv            \n",
      "  inflating: data/sample_submission.csv  \n",
      "  inflating: data/stores.csv         \n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/train.csv          \n",
      "  inflating: data/transactions.csv   \n"
     ]
    }
   ],
   "source": [
    "!unzip store-sales-time-series-forecasting.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56df189-4d12-4acb-a656-27813d6b1e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "holidays_events = pd.read_csv('data/holidays_events.csv')\n",
    "oil = pd.read_csv('data/oil.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "stores = pd.read_csv('data/stores.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "transactions = pd.read_csv('data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db6c48d-a851-4e62-848d-a5dd39c19700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm store-sales-time-series-forecasting.zip\n",
    "!rm -rf data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1a300-55fa-4a3e-9339-17507851bafd",
   "metadata": {},
   "source": [
    "# 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a11cc8-251d-4485-820d-ac567414d0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000883</th>\n",
       "      <td>3000883</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000884</th>\n",
       "      <td>3000884</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000885</th>\n",
       "      <td>3000885</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>3000886</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>3000887</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000888 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id        date  store_nbr                      family     sales  \\\n",
       "0              0  2013-01-01          1                  AUTOMOTIVE     0.000   \n",
       "1              1  2013-01-01          1                   BABY CARE     0.000   \n",
       "2              2  2013-01-01          1                      BEAUTY     0.000   \n",
       "3              3  2013-01-01          1                   BEVERAGES     0.000   \n",
       "4              4  2013-01-01          1                       BOOKS     0.000   \n",
       "...          ...         ...        ...                         ...       ...   \n",
       "3000883  3000883  2017-08-15          9                     POULTRY   438.133   \n",
       "3000884  3000884  2017-08-15          9              PREPARED FOODS   154.553   \n",
       "3000885  3000885  2017-08-15          9                     PRODUCE  2419.729   \n",
       "3000886  3000886  2017-08-15          9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "3000887  3000887  2017-08-15          9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "3000883            0  \n",
       "3000884            1  \n",
       "3000885          148  \n",
       "3000886            8  \n",
       "3000887            0  \n",
       "\n",
       "[3000888 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4928381-6e67-449a-bf86-f035180bf6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>3002665</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>3002666</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>3002667</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>3002668</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>3002669</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date  store_nbr                      family  onpromotion\n",
       "0     3000888  2017-08-16          1                  AUTOMOTIVE            0\n",
       "1     3000889  2017-08-16          1                   BABY CARE            0\n",
       "2     3000890  2017-08-16          1                      BEAUTY            2\n",
       "3     3000891  2017-08-16          1                   BEVERAGES           20\n",
       "4     3000892  2017-08-16          1                       BOOKS            0\n",
       "...       ...         ...        ...                         ...          ...\n",
       "1777  3002665  2017-08-16          9                     POULTRY            0\n",
       "1778  3002666  2017-08-16          9              PREPARED FOODS            1\n",
       "1779  3002667  2017-08-16          9                     PRODUCE          158\n",
       "1780  3002668  2017-08-16          9  SCHOOL AND OFFICE SUPPLIES           14\n",
       "1781  3002669  2017-08-16          9                     SEAFOOD            0\n",
       "\n",
       "[1782 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['date']=='2017-08-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b473b7-8e61-46aa-8915-56f88f92d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    target=\"sales\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5b780d-8c5d-46fb-8daf-f85788a29934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'AutogluonModels/ag-20231205_065756'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #26~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Jul 13 16:27:29 UTC 2\n",
      "CPU Count:          16\n",
      "GPU Count:          0\n",
      "Memory Avail:       117.29 GB / 125.71 GB (93.3%)\n",
      "Disk Space Avail:   220.22 GB / 456.88 GB (48.2%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 1,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'target': 'sales',\n",
      " 'verbosity': 2}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Frequency of train_data is not provided and cannot be inferred. Please set the expected data frequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that the data has a regular time index with `train_data.convert_frequency(freq=...)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m predictr \u001b[38;5;241m=\u001b[39m TimeSeriesPredictor(target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# step3 \u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpredictr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/timeseries/predictor.py:644\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, hyperparameter_tune_kwargs, excluded_model_types, num_val_windows, val_step_size, refit_every_n_windows, refit_full, enable_ensemble, random_seed, verbosity)\u001b[0m\n\u001b[1;32m    641\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFitting with arguments:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    642\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpprint\u001b[38;5;241m.\u001b[39mpformat({k:\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mk,\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mfit_args\u001b[38;5;241m.\u001b[39mitems()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m})\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 644\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_and_prepare_data_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided train_data has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_stats(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_step_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/timeseries/predictor.py:268\u001b[0m, in \u001b[0;36mTimeSeriesPredictor._check_and_prepare_data_frame\u001b[0;34m(self, data, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not provided and cannot be inferred. Please set the expected data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe data has a regular time index with `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.convert_frequency(freq=...)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfreq\n",
      "\u001b[0;31mValueError\u001b[0m: Frequency of train_data is not provided and cannot be inferred. Please set the expected data frequency when creating the predictor with `TimeSeriesPredictor(freq=...)` or ensure that the data has a regular time index with `train_data.convert_frequency(freq=...)`"
     ]
    }
   ],
   "source": [
    "# step1 \n",
    "ts_train = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_train,\n",
    "    id_column=\"id\",\n",
    "    timestamp_column=\"date\"\n",
    ")\n",
    "# step2 \n",
    "predictr = TimeSeriesPredictor(target='sales')\n",
    "# step3 \n",
    "predictr.fit(ts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa6558-c7d8-4e61-b9bc-84d064cbdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5454954-6cb2-4ca5-b3af-ebbf44f3d391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTimeSeriesPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mknown_covariates_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfreq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_metric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautogluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeSeriesScorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_metric_seasonal_period\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbosity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquantile_levels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_predictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearner_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mautogluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstract_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbstractLearner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearner_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "AutoGluon ``TimeSeriesPredictor`` predicts future values of multiple related time series.\n",
       "\n",
       "``TimeSeriesPredictor`` provides probabilistic (quantile) multi-step-ahead forecasts for univariate time series.\n",
       "The forecast includes both the mean (i.e., conditional expectation of future values given the past), as well as the\n",
       "quantiles of the forecast distribution, indicating the range of possible future outcomes.\n",
       "\n",
       "``TimeSeriesPredictor`` fits both \"global\" deep learning models that are shared across all time series\n",
       "(e.g., DeepAR, Transformer), as well as \"local\" statistical models that are fit to each individual time series\n",
       "(e.g., ARIMA, ETS).\n",
       "\n",
       "``TimeSeriesPredictor`` expects input data and makes predictions in the\n",
       ":class:`~autogluon.timeseries.TimeSeriesDataFrame` format.\n",
       "\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "target : str, default = \"target\"\n",
       "    Name of column that contains the target values to forecast (i.e., numeric observations of the time series).\n",
       "prediction_length : int, default = 1\n",
       "    The forecast horizon, i.e., How many time steps into the future the models should be trained to predict.\n",
       "    For example, if time series contain daily observations, setting ``prediction_length = 3`` will train\n",
       "    models that predict up to 3 days into the future from the most recent observation.\n",
       "freq : str, optional\n",
       "    Frequency of the time series data (see `pandas documentation <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_\n",
       "    for available frequencies). For example, ``\"D\"`` for daily data or ``\"H\"`` for hourly data.\n",
       "\n",
       "    By default, the predictor will attempt to automatically infer the frequency from the data. This argument should\n",
       "    only be set in two cases:\n",
       "\n",
       "    1. The time series data has irregular timestamps, so frequency cannot be inferred automatically.\n",
       "    2. You would like to resample the original data at a different frequency (for example, convert hourly measurements into daily measurements).\n",
       "\n",
       "    If ``freq`` is provided when creating the predictor, all data passed to the predictor will be automatically\n",
       "    resampled at this frequency.\n",
       "eval_metric : Union[str, TimeSeriesScorer], default = \"WQL\"\n",
       "    Metric by which predictions will be ultimately evaluated on future test data. AutoGluon tunes hyperparameters\n",
       "    in order to improve this metric on validation data, and ranks models (on validation data) according to this\n",
       "    metric.\n",
       "\n",
       "    Probabilistic forecast metrics (evaluated on quantile forecasts for the specified ``quantile_levels``):\n",
       "\n",
       "    - ``\"SQL\"``: scaled quantile loss\n",
       "    - ``\"WQL\"``: weighted quantile loss\n",
       "\n",
       "    Point forecast metrics (these are always evaluated on the ``\"mean\"`` column of the predictions):\n",
       "\n",
       "    - ``\"MAE\"``: mean absolute error\n",
       "    - ``\"MAPE\"``: mean absolute percentage error\n",
       "    - ``\"MASE\"``: mean absolute scaled error\n",
       "    - ``\"MSE\"``: mean squared error\n",
       "    - ``\"RMSE\"``: root mean squared error\n",
       "    - ``\"RMSSE\"``: root mean squared scaled error\n",
       "    - ``\"SMAPE\"``: \"symmetric\" mean absolute percentage error\n",
       "    - ``\"WAPE\"``: weighted absolute percentage error\n",
       "\n",
       "    For more information about these metrics, see :ref:`Forecasting Time Series - Evaluation Metrics <forecasting_metrics>`.\n",
       "eval_metric_seasonal_period : int, optional\n",
       "    Seasonal period used to compute some evaluation metrics such as mean absolute scaled error (MASE). Defaults to\n",
       "    ``None``, in which case the seasonal period is computed based on the data frequency.\n",
       "known_covariates_names: List[str], optional\n",
       "    Names of the covariates that are known in advance for all time steps in the forecast horizon. These are also\n",
       "    known as dynamic features, exogenous variables, additional regressors or related time series. Examples of such\n",
       "    covariates include holidays, promotions or weather forecasts.\n",
       "\n",
       "    Currently, only numeric (float of integer dtype) are supported.\n",
       "\n",
       "    If ``known_covariates_names`` are provided, then:\n",
       "\n",
       "    - :meth:`~autogluon.timeseries.TimeSeriesPredictor.fit`, :meth:`~autogluon.timeseries.TimeSeriesPredictor.evaluate`, and :meth:`~autogluon.timeseries.TimeSeriesPredictor.leaderboard` will expect a data frame with columns listed in ``known_covariates_names`` (in addition to the ``target`` column).\n",
       "    - :meth:`~autogluon.timeseries.TimeSeriesPredictor.predict` will expect an additional keyword argument ``known_covariates`` containing the future values of the known covariates in ``TimeSeriesDataFrame`` format.\n",
       "\n",
       "quantile_levels : List[float], optional\n",
       "    List of increasing decimals that specifies which quantiles should be estimated when making distributional\n",
       "    forecasts. Defaults to ``[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]``.\n",
       "path : str or pathlib.Path, optional\n",
       "    Path to the directory where models and intermediate outputs will be saved. Defaults to a timestamped folder\n",
       "    ``AutogluonModels/ag-[TIMESTAMP]`` that will be created in the working directory.\n",
       "verbosity : int, default = 2\n",
       "    Verbosity levels range from 0 to 4 and control how much information is printed to stdout. Higher levels\n",
       "    correspond to more detailed print statements, and ``verbosity=0`` suppresses output including warnings.\n",
       "    If using ``logging``, you can alternatively control amount of information printed via ``logger.setLevel(L)``,\n",
       "    where ``L`` ranges from 0 to 50 (Note: higher values of ``L`` correspond to fewer print statements, opposite\n",
       "    of verbosity levels).\n",
       "cache_predictions : bool, default = True\n",
       "    If True, the predictor will cache and reuse the predictions made by individual models whenever\n",
       "    :meth:`~autogluon.timeseries.TimeSeriesPredictor.predict`, :meth:`~autogluon.timeseries.TimeSeriesPredictor.leaderboard`,\n",
       "    or :meth:`~autogluon.timeseries.TimeSeriesPredictor.evaluate` methods are called. This allows to significantly\n",
       "    speed up these methods. If False, caching will be disabled. You can set this argument to False to reduce disk\n",
       "    usage at the cost of longer prediction times.\n",
       "label : str, optional\n",
       "    Alias for :attr:`target`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/timeseries/predictor.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TimeSeriesPredictor(target='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297caef7-6ece-48bc-b7f5-77e47f014720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>3029395</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>3029396</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>3029397</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>3029398</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>3029399</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        date  store_nbr                      family  onpromotion\n",
       "0      3000888  2017-08-16          1                  AUTOMOTIVE            0\n",
       "1      3000889  2017-08-16          1                   BABY CARE            0\n",
       "2      3000890  2017-08-16          1                      BEAUTY            2\n",
       "3      3000891  2017-08-16          1                   BEVERAGES           20\n",
       "4      3000892  2017-08-16          1                       BOOKS            0\n",
       "...        ...         ...        ...                         ...          ...\n",
       "28507  3029395  2017-08-31          9                     POULTRY            1\n",
       "28508  3029396  2017-08-31          9              PREPARED FOODS            0\n",
       "28509  3029397  2017-08-31          9                     PRODUCE            1\n",
       "28510  3029398  2017-08-31          9  SCHOOL AND OFFICE SUPPLIES            9\n",
       "28511  3029399  2017-08-31          9                     SEAFOOD            0\n",
       "\n",
       "[28512 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bfce9-0dbb-4d19-a609-ce8cebd542ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
